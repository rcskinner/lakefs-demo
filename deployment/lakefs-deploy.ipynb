{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using `LakeFS` to Drive Value in Development\n",
    "\n",
    "LakeFS is an essential tool for modern day development teams who are working with data lakes (S3, Azure Data Lake). LakeFS provides version control, backup, and workflow management soulutions that allow technical teams to: \n",
    "- **Experiment:** Safely experiment with copies of the production data lake without risking data lake contaimination \n",
    "- **Collaborate:** Collaborate with other engineering teams on the development of engineering workflows\n",
    "\n",
    "When working with a data lake without LakeFS engineering teams have the tough choice of: \n",
    "1. Slow down development by prohibiting in-situ experimentation and testing with production data\n",
    "2. Digitally copy Data Lake data multiplying storage and hosting costs \n",
    "3. Risk contaimination of the Datalake resulting in expensive rollback procedure, loss of newly generated data, & duplication of storage\n",
    "\n",
    "![Image](https://lakefs.io/wp-content/uploads/2022/03/Share-image_1200x630-2.png)\n",
    "\n",
    "LakeFS provides a highly scalable format agnostic zero copy operations that allow developers and engineering teams to manage their data like code. This demonstration will cover the following topics:\n",
    "\n",
    "- Configuration of the LakeFS Client / Overview of the LakeFS Admin UI \n",
    "- Interfacing with LakeFS via the Python API \n",
    "- Initializing repositories and creating new branches \n",
    "- Adding data to branches \n",
    "    - Adding, committing \n",
    "    - Version differencing\n",
    "    - Merge operations\n",
    "- Protecting valuable production data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the LakeFS Client and Connect\n",
    "----\n",
    "We'll pull in the appropriate imports and change the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rskin\\lakefs-demo\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries and change working directory\n",
    "%cd \"C:\\Users\\rskin\\lakefs-demo\"\n",
    "import os\n",
    "from pathlib import Path, PurePosixPath\n",
    "\n",
    "import lakefs_client\n",
    "from lakefs_client import models\n",
    "from lakefs_client.client import LakeFSClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the LakeFS client to connect to the service\n",
    "configuration = lakefs_client.Configuration()\n",
    "configuration.host = 'https://adapted-husky.lakefs-demo.io'\n",
    "configuration.username = \"AKIAJRRULG47CCC5Q6QQ\"\n",
    "configuration.password = \"JSHymZ3sCBwhrHQlJCq4rYDKC/MY4/NzExoVaLdH\"\n",
    "client = LakeFSClient(configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initalize a new Repository and create a new branch\n",
    "\n",
    "In this section we'll create a new repository `stock-data`. We'll then create a branch called `data-upload` that we'll use to load our first set of Exchange Traded Fund (ETF) data. This section will cover the following concepts\n",
    "- Initializing a new repository\n",
    "- Creating a new branch \n",
    "- Creating a protected branch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a repository \n",
    "name = 'stock-data'\n",
    "repo = models.RepositoryCreation(\n",
    "    name= name, \n",
    "    storage_namespace='s3://treeverse-demo-lakefs-storage-production/user_adapted-husky/stock-data', \n",
    "    default_branch='main')\n",
    "client.repositories.create_repository(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.branches.create_branch(\n",
    "    repository='stock-data', \n",
    "    branch_creation=models.BranchCreation(name='data-upload', source='main')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Data to branches\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name = 'stock-data'\n",
    "def upload_data(branch:str,fname:str, lfs_client:LakeFSClient = client, repository:str = repo_name):\n",
    "    \"\"\"Add data to the specified LakeFS Repositry / Branch\"\"\"\n",
    "    with open(fname, 'r', encoding='utf8', errors='ignore') as f:\n",
    "        client.objects.upload_object(repository=repository, branch=branch, path=fname,content=f)\n",
    "\n",
    "def upload_dir(directory:str, branch:str,  repository:str = repo_name):\n",
    "    \"\"\"Upload all files in a directory to LakeFS \"\"\"\n",
    "    directory = Path(directory)\n",
    "    for filename in os.listdir(directory):\n",
    "        path = PurePosixPath(directory / filename)\n",
    "        path = str(path)\n",
    "        upload_data(branch='data-upload', fname= path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_data('data-upload', 'stock-data/Stocks/aau.us.txt')\n",
    "upload_data('data-upload','stock-data/ETFs/aaxj.us.txt')\n",
    "upload_dir('stock-data/ETFs', 'data-upload')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a75908cf41ea5be0db61fa6abf8b7a151ad4355677d7ee25492eb64cb967730"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('lakefs-demo-utJ5wb3e-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
